# ğŸ”„ Model Update Guide - Question-Aware BERT Model

## âœ… ÄÃ£ hoÃ n thÃ nh

1. **Backup**: File `ml_assess.py` cÅ© Ä‘Ã£ Ä‘Æ°á»£c backup thÃ nh `ml_assess.py.backup`
2. **Copy model má»›i**: File `ml_assess.py` má»›i Ä‘Ã£ Ä‘Æ°á»£c copy tá»« Downloads
3. **Update service**: `writing_scorer.py` Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ sá»­ dá»¥ng `QuestionAssessor`

## ğŸ“‹ Thay Ä‘á»•i chÃ­nh

### Model má»›i: `QuestionAssessor`
- **Question Awareness**: Model má»›i cÃ³ thá»ƒ sá»­ dá»¥ng question/prompt Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c hÆ¡n
- **Attention Layer**: Sá»­ dá»¥ng self-attention mechanism
- **BiLSTM**: Bidirectional LSTM layer
- **Feature Dimension**: 
  - Without question: 768 (essay only)
  - With question: 1536 (essay 768 + question 768)

### API Changes
- `predict_with_active_model()` bÃ¢y giá» nháº­n thÃªm parameter `prompt`
- Model tá»± Ä‘á»™ng sá»­ dá»¥ng prompt lÃ m question náº¿u cÃ³
- Backward compatible vá»›i model cÅ©

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Option 1: Sá»­ dá»¥ng model Ä‘Ã£ train sáºµn
Náº¿u báº¡n Ä‘Ã£ cÃ³ model Ä‘Æ°á»£c train sáºµn trong `bert_question_model/`:
```bash
# Model sáº½ tá»± Ä‘á»™ng load khi start service
cd python-services
python writing_scorer.py
```

### Option 2: Train model má»›i
Náº¿u chÆ°a cÃ³ model, báº¡n cáº§n train:
```python
from ml_assess import QuestionAssessor

# Initialize vá»›i question awareness
assessor = QuestionAssessor(
    max_length=512,
    use_question=True
)

# Load data
df = assessor.load_data('path/to/ielts_dataset.csv')

# Prepare training data
X_train, X_test, y_train, y_test, y_train_orig, y_test_orig = \
    assessor.prepare_training_data(df)

# Train
history = assessor.train(X_train, y_train, X_test, y_test, epochs=50)

# Save model
assessor.save_model('./bert_question_model')
```

## ğŸ“ Cáº¥u trÃºc file

```
ai-models/writing-scorer/
â”œâ”€â”€ ml_assess.py                    # âœ… Model QuestionAssessor Ä‘ang dÃ¹ng
â”œâ”€â”€ bert_question_model/            # âš ï¸ Model Ä‘Ã£ train (báº¯t buá»™c pháº£i cÃ³)
â”‚   â”œâ”€â”€ model.keras
â”‚   â””â”€â”€ metadata.pkl
â””â”€â”€ README.md (tÃ¹y chá»n)            # Ghi chÃº nhanh vá» model

Legacy assets (IELTS_Model, bert_ielts_model, ...) Ä‘Ã£ Ä‘Æ°á»£c dá»n sang
`ai-models/backup/` Ä‘á»ƒ thÆ° má»¥c chÃ­nh gá»n gÃ ng hÆ¡n.
```

## ğŸ” Model Loading Priority

Service giá» chá»‰ táº­p trung vÃ o **BERT Question-Aware** (`bert_question_model/`).
Náº¿u thÆ° má»¥c nÃ y khÃ´ng tá»“n táº¡i, service sáº½ rÆ¡i vá» fallback logic cÅ© (heuristic scoring).
CÃ¡c model legacy váº«n cÃ³ thá»ƒ khÃ´i phá»¥c tá»« `ai-models/backup/` náº¿u tháº­t sá»± cáº§n.

## ğŸ§ª Test Model

### Test vá»›i Python:
```python
from ml_assess import QuestionAssessor

assessor = QuestionAssessor()
assessor.load_model('./bert_question_model')

# Test vá»›i question
result = assessor.predict(
    essay="Your essay text here...",
    task_type=2,
    question="Your question/prompt here..."
)

print(f"Score: {result['score']}")
print(f"Band: {result['band']}")
```

### Test vá»›i API:
```bash
curl -X POST http://localhost:5001/score-ai \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Your essay text...",
    "prompt": "Your question/prompt..."
  }'
```

## âš ï¸ LÆ°u Ã½

1. **Model chÆ°a train**: Náº¿u chÆ°a cÃ³ `bert_question_model/`, service sáº½ fallback vá» thuáº­t toÃ¡n heuristic (Ä‘á»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n). CÃ³ thá»ƒ khÃ´i phá»¥c model cÅ© tá»« `ai-models/backup/legacy-models/` khi cáº§n.
2. **Question lÃ  optional**: Model váº«n hoáº¡t Ä‘á»™ng náº¿u khÃ´ng cÃ³ question (sáº½ chá»‰ dÃ¹ng essay features)
3. **Metadata**: Model má»›i lÆ°u `use_question` flag trong metadata.pkl
4. **Backward compatibility**: Code váº«n há»— trá»£ model cÅ© (`PMCStyleIELTSAssessor`), nhÆ°ng cÃ¡c file Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn vÃ o thÆ° má»¥c `backup`.

## ğŸ“ Next Steps

1. **Train model má»›i** (náº¿u chÆ°a cÃ³):
   - Chuáº©n bá»‹ dataset vá»›i cá»™t `Question` vÃ  `Essay`
   - Cháº¡y training script
   - Save model vÃ o `bert_question_model/`

2. **Test model**:
   - Start Python service
   - Test vá»›i writing page
   - Verify question awareness hoáº¡t Ä‘á»™ng

3. **Monitor performance**:
   - So sÃ¡nh accuracy vá»›i model cÅ©
   - Kiá»ƒm tra response time
   - Verify question awareness cáº£i thiá»‡n scoring

## ğŸ”— Files Changed

- âœ… `ai-models/writing-scorer/ml_assess.py` - Model má»›i
- âœ… `python-services/writing_scorer.py` - Service updated
- âœ… `ai-models/writing-scorer/ml_assess.py.backup` - Backup

## ğŸ“ Support

Náº¿u cÃ³ váº¥n Ä‘á»:
1. Kiá»ƒm tra log khi start service
2. Verify model files tá»“n táº¡i
3. Check metadata.pkl cÃ³ Ä‘Ãºng format
4. Test vá»›i model cÅ© trÆ°á»›c (fallback)

